{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, activation=None, input_shape=None):\n",
    "        self.activation = activation\n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    def init(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = input_shape\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return x\n",
    "    \n",
    "    def relu(self, x):\n",
    "        zeros = np.zeros_like(x)\n",
    "        return np.where(x > zeros, x, zeros)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp = np.exp(x)\n",
    "        exp_sum = np.sum(exp)\n",
    "        return exp / exp_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, units, activation=\"relu\", input_shape=None):\n",
    "        super().__init__(activation=activation, input_shape=input_shape)\n",
    "        self.units = units\n",
    "    \n",
    "    def init(self, input_shape):\n",
    "        super().init(input_shape)\n",
    "        self.weights = np.zeros((input_shape[0], self.units))\n",
    "        self.biases = np.zeros(self.units)\n",
    "        self.output_shape = (self.units, )\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y = np.dot(x, self.weights) + self.biases\n",
    "        \n",
    "        if self.activation == \"relu\":\n",
    "            y = self.relu(y)\n",
    "        elif self.activation == \"softmax\":\n",
    "            y = self.softmax(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(Layer):\n",
    "    def __init__(self, filters, kernel_size, activation=\"relu\", input_shape=None):\n",
    "        super().__init__(activation=activation, input_shape=input_shape)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def init(self, input_shape):\n",
    "        super().init(input_shape)\n",
    "        self.weights = np.zeros((self.kernel_size[0], self.kernel_size[1], input_shape[2], self.filters))\n",
    "        self.biases = np.zeros(self.filters)\n",
    "        self.output_shape = (input_shape[0], input_shape[1], self.filters)\n",
    "        self.padding_number = ((self.kernel_size[0] - 1) // 2, (self.kernel_size[1] - 1) // 2)\n",
    "    \n",
    "    def zero_pad(self, image):\n",
    "        image_padded = np.empty((image.shape[0] + self.padding_number[0] * 2, image.shape[1] + self.padding_number[1] * 2, image.shape[2]))\n",
    "        for channel_idx in range(image.shape[2]):\n",
    "            image_channel_padded = image[:, :, channel_idx]\n",
    "            image_channel_padded = np.insert(image_channel_padded, [0] * self.padding_number[0] + [image.shape[1]] * self.padding_number[0], 0, axis=0)\n",
    "            image_channel_padded = np.insert(image_channel_padded, [0] * self.padding_number[1] + [image.shape[1]] * self.padding_number[1], 0, axis=1)\n",
    "            image_padded[:, :, channel_idx] = image_channel_padded\n",
    "        return image_padded\n",
    "    \n",
    "    def convolve(self, image, kernel):\n",
    "        convoluted = np.zeros((self.output_shape[0], self.output_shape[1]))\n",
    "        for row_idx in range(self.output_shape[0]):\n",
    "            row_start = row_idx\n",
    "            row_end = row_start + self.kernel_size[0]\n",
    "            for col_idx in range(self.output_shape[1]):\n",
    "                col_start = col_idx\n",
    "                col_end = col_start + self.kernel_size[1]\n",
    "                receptive_field = image[row_start:row_end, col_start:col_end]\n",
    "                convoluted[row_idx, col_idx] = np.sum(receptive_field * kernel)\n",
    "        return convoluted\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x_padded = self.zero_pad(x)\n",
    "        \n",
    "        y = np.zeros(self.output_shape)\n",
    "        \n",
    "        for filter_idx in range(self.filters):\n",
    "            feature_map = np.zeros((self.output_shape[0], self.output_shape[1]))\n",
    "            for channel_idx in range(x_padded.shape[2]):\n",
    "                feature_map += self.convolve(x_padded[:, :, channel_idx], self.weights[:, :, channel_idx, filter_idx])\n",
    "            feature_map += self.biases[filter_idx]\n",
    "            y[:, :, filter_idx] = feature_map\n",
    "        \n",
    "        if self.activation == \"relu\":\n",
    "            y = self.relu(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling2D(Layer):\n",
    "    def __init__(self, pool_size, strides, input_shape=None):\n",
    "        super().__init__(input_shape=input_shape)\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "    \n",
    "    def init(self, input_shape):\n",
    "        super().init(input_shape)\n",
    "        self.output_shape = ((input_shape[0] - self.pool_size[0]) // self.strides[0] + 1, (input_shape[1] - self.pool_size[1]) // self.strides[1] + 1, input_shape[2])\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y = np.zeros(self.output_shape)\n",
    "        \n",
    "        for row_idx in range(self.output_shape[0]):\n",
    "            row_start = row_idx * self.pool_size[0]\n",
    "            row_end = row_start + self.pool_size[0]\n",
    "            for col_idx in range(self.output_shape[1]):\n",
    "                col_start = col_idx * self.pool_size[1]\n",
    "                col_end = col_start + self.pool_size[1]\n",
    "                for channel_idx in range(self.output_shape[2]):\n",
    "                    y[row_idx, col_idx, channel_idx] = np.max(x[row_start:row_end, col_start:col_end, channel_idx])\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(Layer):\n",
    "    def __init__(self, input_shape=None):\n",
    "        super().__init__(input_shape=input_shape)\n",
    "    \n",
    "    def init(self, input_shape):\n",
    "        super().init(input_shape)\n",
    "        self.output_shape = (np.prod(np.array(input_shape)), )\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return x.reshape(self.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.input_shape = ()\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        if len(self.layers) == 1:\n",
    "            self.input_shape = layer.input_shape\n",
    "    \n",
    "    def compile(self, optimizer=\"sgd\", loss=\"categorical_crossentropy\"):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        \n",
    "        input_shape = self.input_shape\n",
    "        for i in range(len(self.layers)):\n",
    "            self.layers[i].init(input_shape)\n",
    "            input_shape = self.layers[i].output_shape\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        ys = np.empty((xs.shape[0], self.layers[-1].output_shape[0]))\n",
    "        \n",
    "        for i, x in enumerate(xs):\n",
    "            y = x\n",
    "            for layer in self.layers:\n",
    "                y = layer.predict(y)\n",
    "            ys[i, :] = y\n",
    "        \n",
    "        return ys\n",
    "    \n",
    "    def error(self, xs, labels):\n",
    "        ys = self.predict(xs)\n",
    "        \n",
    "        if self.loss == \"categorical_crossentropy\":\n",
    "            return -np.sum(labels * np.log(ys))\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2), (2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2), (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "test_data = mnist.test.images\n",
    "test_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape((-1, 28, 28, 1))\n",
    "train_labels = np.array([[0] * train_label + [1] + [0] * (9 - train_label) for train_label in train_labels])\n",
    "test_data = test_data.reshape((-1, 28, 28, 1))\n",
    "test_labels = np.array([[0] * test_label + [1] + [0] * (9 - test_label) for test_label in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
